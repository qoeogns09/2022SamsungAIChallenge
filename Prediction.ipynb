{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfb6177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qoeogns09/miniconda3/envs/samsungsubmission/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Callable, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from torch_scatter import scatter\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip, Data)\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, radius\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, sort_edge_index\n",
    "\n",
    "from utils import BesselBasisLayer, SphericalBasisLayer, EMA, MLP\n",
    "from layers import Global_MP, Local_MP\n",
    "\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import HybridizationType\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481d399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(1337) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0bc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668475bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Samsung(InMemoryDataset):\n",
    "    if rdkit is not None:\n",
    "        types = {'H':0, 'B':1, 'N':2, 'O':3, 'F':4, 'C':5, 'Si':6, 'P':7, 'S':8, 'Cl':9, 'Br':10, 'I':11}\n",
    "        symbols = {'H':1, 'B':5, 'N':7, 'O':8, 'F':9, 'C':12, 'Si':14, 'P':15, 'S':16, 'Cl':17, 'Br':35, 'I':53}\n",
    "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
    "\n",
    "    def __init__(self, root: str, transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None,\n",
    "                 pre_filter: Optional[Callable] = None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "#     def mean(self, target: int) -> float:\n",
    "#         y = torch.cat([self.get(i).y for i in range(len(self))], dim=0)\n",
    "#         return float(y[:, target].mean())\n",
    "\n",
    "#     def std(self, target: int) -> float:\n",
    "#         y = torch.cat([self.get(i).y for i in range(len(self))], dim=0)\n",
    "#         return float(y[:, target].std())\n",
    "\n",
    "#     def atomref(self, target) -> Optional[torch.Tensor]:\n",
    "#         if target in atomrefs:\n",
    "#             out = torch.zeros(100)\n",
    "#             out[torch.tensor([1, 6, 7, 8, 9])] = torch.tensor(atomrefs[target])\n",
    "#             return out.view(-1, 1)\n",
    "#         return None\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        if rdkit is None:\n",
    "            return ['samsung_test.pt']\n",
    "        else:\n",
    "            return ['samsung_test.sdf', 'samsung_test.sdf.csv', 'uncharacterized.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'samsung_test.pt'\n",
    "\n",
    "    def process(self):\n",
    "        if rdkit is None:\n",
    "            print('Using a pre-processed version of the dataset. Please '\n",
    "                  'install `rdkit` to alternatively process the raw data.')\n",
    "\n",
    "            self.data, self.slices = torch.load(self.raw_paths[0])\n",
    "            data_list = [self.get(i) for i in range(len(self))]\n",
    "\n",
    "            if self.pre_filter is not None:\n",
    "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "            torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "            return\n",
    "\n",
    "        data_list = []\n",
    "        max_dist = 0\n",
    "        for idx, i in enumerate(tqdm(test_df[test_df.columns[0]])):\n",
    "            g_mol = Chem.MolFromMolFile(f'data/mol_files/test_set/{i}' + '_g.mol', removeHs=False, sanitize=False)\n",
    "            ex_mol = Chem.MolFromMolFile(f'data/mol_files/test_set/{i}' + '_ex.mol', removeHs=False, sanitize=False)\n",
    "\n",
    "            N = g_mol.GetNumAtoms()\n",
    "\n",
    "            tmp_g = pd.read_csv(f\"data/test_g_file/{i}\" + '_g.csv')\n",
    "            tmp_ex = pd.read_csv(f\"data/test_ex_file/{i}\" + '_ex.csv')\n",
    "\n",
    "            pos_g = np.array(tmp_g[['0', '1', '2']])\n",
    "            pos_ex = np.array(tmp_ex[['0', '1', '2']])\n",
    "\n",
    "            pos_g = torch.tensor(pos_g, dtype=torch.float)\n",
    "            pos_ex = torch.tensor(pos_ex, dtype=torch.float)\n",
    "\n",
    "            type_idx = []\n",
    "            atomic_number = []\n",
    "            aromatic = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            num_hs = []\n",
    "            \n",
    "            for atom in g_mol.GetAtoms():\n",
    "                type_idx.append(self.types[atom.GetSymbol()])\n",
    "                atomic_number.append(atom.GetAtomicNum())\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                hybridization = atom.GetHybridization()\n",
    "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "\n",
    "            z = torch.tensor(atomic_number, dtype=torch.long)\n",
    "\n",
    "            row, col, edge_type = [], [], []\n",
    "            for bond in g_mol.GetBonds():\n",
    "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "                row += [start, end]\n",
    "                col += [end, start]\n",
    "                edge_type += 2 * [self.bonds[bond.GetBondType()]]\n",
    "\n",
    "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "            edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "            edge_attr = F.one_hot(edge_type,\n",
    "                                  num_classes=len(self.bonds)).to(torch.float)\n",
    "\n",
    "            perm = (edge_index[0] * N + edge_index[1]).argsort()\n",
    "            edge_index = edge_index[:, perm]\n",
    "            edge_type = edge_type[perm]\n",
    "            edge_attr = edge_attr[perm]\n",
    "\n",
    "            row, col = edge_index\n",
    "            hs = (z == 1).to(torch.float)\n",
    "            num_hs = scatter(hs[row], col, dim_size=N).tolist()\n",
    "\n",
    "            x = torch.tensor(type_idx).to(torch.float)\n",
    "\n",
    "            data = Data(x=x, z=z, pos_g=pos_g, pos_ex=pos_ex, edge_index=edge_index,\n",
    "                        edge_attr=edge_attr, name=i, idx=idx)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d08c056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of graphs: 457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qoeogns09/miniconda3/envs/samsungsubmission/lib/python3.7/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "path = 'data/samsung'\n",
    "test_dataset = Samsung(path)\n",
    "print('# of graphs:', len(test_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:3') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "n_layer = 6\n",
    "dim = 128\n",
    "cutoff = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119a9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model):\n",
    "    error = 0\n",
    "    ema.assign(model)\n",
    "    with torch.no_grad():\n",
    "        pred = []\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred.append(output.cpu())\n",
    "    ema.resume(model)\n",
    "    return torch.cat(pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0941fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, dim, n_layer, cutoff):\n",
    "        self.dim = dim\n",
    "        self.n_layer = n_layer\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "class MXMNetG(nn.Module):\n",
    "    def __init__(self, config: Config, num_spherical=7, num_radial=6, envelope_exponent=5):\n",
    "        super(MXMNetG, self).__init__()\n",
    "\n",
    "        self.dim = config.dim\n",
    "        self.n_layer = config.n_layer\n",
    "        self.cutoff = config.cutoff\n",
    "\n",
    "        self.embeddings = nn.Parameter(torch.ones((12, self.dim)))\n",
    "\n",
    "        self.rbf_l = BesselBasisLayer(16, 5, envelope_exponent)\n",
    "        self.rbf_g = BesselBasisLayer(16, self.cutoff, envelope_exponent)\n",
    "        self.sbf = SphericalBasisLayer(num_spherical, num_radial, 5, envelope_exponent)\n",
    "\n",
    "        self.rbf_g_mlp = MLP([16, self.dim])\n",
    "        self.rbf_l_mlp = MLP([16, self.dim])\n",
    "\n",
    "        self.sbf_1_mlp = MLP([num_spherical * num_radial, self.dim])\n",
    "        self.sbf_2_mlp = MLP([num_spherical * num_radial, self.dim])\n",
    "\n",
    "        self.global_layers = torch.nn.ModuleList()\n",
    "        for layer in range(config.n_layer):\n",
    "            self.global_layers.append(Global_MP(config))\n",
    "\n",
    "        self.local_layers = torch.nn.ModuleList()\n",
    "        for layer in range(config.n_layer):\n",
    "            self.local_layers.append(Local_MP(config))\n",
    "        \n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        stdv = math.sqrt(3)\n",
    "        self.embeddings.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def indices(self, edge_index, num_nodes):\n",
    "        row, col = edge_index\n",
    "\n",
    "        value = torch.arange(row.size(0), device=row.device)\n",
    "        adj_t = SparseTensor(row=col, col=row, value=value,\n",
    "                             sparse_sizes=(num_nodes, num_nodes))\n",
    "        \n",
    "        #Compute the node indices for two-hop angles\n",
    "        adj_t_row = adj_t[row]\n",
    "        num_triplets = adj_t_row.set_value(None).sum(dim=1).to(torch.long)\n",
    "\n",
    "        idx_i = col.repeat_interleave(num_triplets)\n",
    "        idx_j = row.repeat_interleave(num_triplets)\n",
    "        idx_k = adj_t_row.storage.col()\n",
    "        mask = idx_i != idx_k\n",
    "        idx_i_1, idx_j, idx_k = idx_i[mask], idx_j[mask], idx_k[mask]\n",
    "\n",
    "        idx_kj = adj_t_row.storage.value()[mask]\n",
    "        idx_ji_1 = adj_t_row.storage.row()[mask]\n",
    "\n",
    "        #Compute the node indices for one-hop angles\n",
    "        adj_t_col = adj_t[col]\n",
    "\n",
    "        num_pairs = adj_t_col.set_value(None).sum(dim=1).to(torch.long)\n",
    "        idx_i_2 = row.repeat_interleave(num_pairs)\n",
    "        idx_j1 = col.repeat_interleave(num_pairs)\n",
    "        idx_j2 = adj_t_col.storage.col()\n",
    "\n",
    "        idx_ji_2 = adj_t_col.storage.row()\n",
    "        idx_jj = adj_t_col.storage.value()\n",
    "\n",
    "        return idx_i_1, idx_j, idx_k, idx_kj, idx_ji_1, idx_i_2, idx_j1, idx_j2, idx_jj, idx_ji_2\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        pos = data.pos_g\n",
    "        batch = data.batch\n",
    "        # Initialize node embeddings\n",
    "        h = torch.index_select(self.embeddings, 0, x.long())\n",
    "\n",
    "        # Get the edges and pairwise distances in the local layer\n",
    "        edge_index_l, _ = remove_self_loops(edge_index)\n",
    "        j_l, i_l = edge_index_l\n",
    "        dist_l = (pos[i_l] - pos[j_l]).pow(2).sum(dim=-1).sqrt()\n",
    "        \n",
    "        # Get the edges pairwise distances in the global layer\n",
    "        row, col = radius(pos, pos, self.cutoff, batch, batch, max_num_neighbors=500)\n",
    "        edge_index_g = torch.stack([row, col], dim=0)\n",
    "        edge_index_g, _ = remove_self_loops(edge_index_g)\n",
    "        j_g, i_g = edge_index_g\n",
    "        dist_g = (pos[i_g] - pos[j_g]).pow(2).sum(dim=-1).sqrt()\n",
    "        \n",
    "        # Compute the node indices for defining the angles\n",
    "        idx_i_1, idx_j, idx_k, idx_kj, idx_ji, idx_i_2, idx_j1, idx_j2, idx_jj, idx_ji_2 = self.indices(edge_index_l, num_nodes=h.size(0))\n",
    "\n",
    "        # Compute the two-hop angles\n",
    "        pos_ji_1, pos_kj = pos[idx_j] - pos[idx_i_1], pos[idx_k] - pos[idx_j]\n",
    "        a = (pos_ji_1 * pos_kj).sum(dim=-1)\n",
    "        b = torch.cross(pos_ji_1, pos_kj).norm(dim=-1)\n",
    "        angle_1 = torch.atan2(b, a)\n",
    "\n",
    "        # Compute the one-hop angles\n",
    "        pos_ji_2, pos_jj = pos[idx_j1] - pos[idx_i_2], pos[idx_j2] - pos[idx_j1]\n",
    "        a = (pos_ji_2 * pos_jj).sum(dim=-1)\n",
    "        b = torch.cross(pos_ji_2, pos_jj).norm(dim=-1)\n",
    "        angle_2 = torch.atan2(b, a)\n",
    "\n",
    "        # Get the RBF and SBF embeddings\n",
    "        rbf_g = self.rbf_g(dist_g)\n",
    "        rbf_l = self.rbf_l(dist_l)\n",
    "        sbf_1 = self.sbf(dist_l, angle_1, idx_kj)\n",
    "        sbf_2 = self.sbf(dist_l, angle_2, idx_jj)\n",
    "        \n",
    "        rbf_g = self.rbf_g_mlp(rbf_g)\n",
    "        rbf_l = self.rbf_l_mlp(rbf_l)\n",
    "        sbf_1 = self.sbf_1_mlp(sbf_1)\n",
    "        sbf_2 = self.sbf_2_mlp(sbf_2)\n",
    "        \n",
    "        # Perform the message passing schemes\n",
    "        node_sum = 0\n",
    "\n",
    "        for layer in range(self.n_layer):\n",
    "            h = self.global_layers[layer](h, rbf_g, edge_index_g)\n",
    "            h, t = self.local_layers[layer](h, rbf_l, sbf_1, sbf_2, idx_kj, idx_ji, idx_jj, idx_ji_2, edge_index_l)\n",
    "            node_sum += t\n",
    "        \n",
    "        # Readout\n",
    "        output = global_add_pool(node_sum, batch)\n",
    "        return output.view(-1)\n",
    "    \n",
    "class MXMNetEX(nn.Module):\n",
    "    def __init__(self, config: Config, num_spherical=7, num_radial=6, envelope_exponent=5):\n",
    "        super(MXMNetEX, self).__init__()\n",
    "\n",
    "        self.dim = config.dim\n",
    "        self.n_layer = config.n_layer\n",
    "        self.cutoff = config.cutoff\n",
    "\n",
    "        self.embeddings = nn.Parameter(torch.ones((12, self.dim)))\n",
    "\n",
    "        self.rbf_l = BesselBasisLayer(16, 5, envelope_exponent)\n",
    "        self.rbf_g = BesselBasisLayer(16, self.cutoff, envelope_exponent)\n",
    "        self.sbf = SphericalBasisLayer(num_spherical, num_radial, 5, envelope_exponent)\n",
    "\n",
    "        self.rbf_g_mlp = MLP([16, self.dim])\n",
    "        self.rbf_l_mlp = MLP([16, self.dim])\n",
    "\n",
    "        self.sbf_1_mlp = MLP([num_spherical * num_radial, self.dim])\n",
    "        self.sbf_2_mlp = MLP([num_spherical * num_radial, self.dim])\n",
    "\n",
    "        self.global_layers = torch.nn.ModuleList()\n",
    "        for layer in range(config.n_layer):\n",
    "            self.global_layers.append(Global_MP(config))\n",
    "\n",
    "        self.local_layers = torch.nn.ModuleList()\n",
    "        for layer in range(config.n_layer):\n",
    "            self.local_layers.append(Local_MP(config))\n",
    "        \n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        stdv = math.sqrt(3)\n",
    "        self.embeddings.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def indices(self, edge_index, num_nodes):\n",
    "        row, col = edge_index\n",
    "\n",
    "        value = torch.arange(row.size(0), device=row.device)\n",
    "        adj_t = SparseTensor(row=col, col=row, value=value,\n",
    "                             sparse_sizes=(num_nodes, num_nodes))\n",
    "        \n",
    "        #Compute the node indices for two-hop angles\n",
    "        adj_t_row = adj_t[row]\n",
    "        num_triplets = adj_t_row.set_value(None).sum(dim=1).to(torch.long)\n",
    "\n",
    "        idx_i = col.repeat_interleave(num_triplets)\n",
    "        idx_j = row.repeat_interleave(num_triplets)\n",
    "        idx_k = adj_t_row.storage.col()\n",
    "        mask = idx_i != idx_k\n",
    "        idx_i_1, idx_j, idx_k = idx_i[mask], idx_j[mask], idx_k[mask]\n",
    "\n",
    "        idx_kj = adj_t_row.storage.value()[mask]\n",
    "        idx_ji_1 = adj_t_row.storage.row()[mask]\n",
    "\n",
    "        #Compute the node indices for one-hop angles\n",
    "        adj_t_col = adj_t[col]\n",
    "\n",
    "        num_pairs = adj_t_col.set_value(None).sum(dim=1).to(torch.long)\n",
    "        idx_i_2 = row.repeat_interleave(num_pairs)\n",
    "        idx_j1 = col.repeat_interleave(num_pairs)\n",
    "        idx_j2 = adj_t_col.storage.col()\n",
    "\n",
    "        idx_ji_2 = adj_t_col.storage.row()\n",
    "        idx_jj = adj_t_col.storage.value()\n",
    "\n",
    "        return idx_i_1, idx_j, idx_k, idx_kj, idx_ji_1, idx_i_2, idx_j1, idx_j2, idx_jj, idx_ji_2\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        pos = data.pos_ex\n",
    "        batch = data.batch\n",
    "        # Initialize node embeddings\n",
    "        h = torch.index_select(self.embeddings, 0, x.long())\n",
    "\n",
    "        # Get the edges and pairwise distances in the local layer\n",
    "        edge_index_l, _ = remove_self_loops(edge_index)\n",
    "        j_l, i_l = edge_index_l\n",
    "        dist_l = (pos[i_l] - pos[j_l]).pow(2).sum(dim=-1).sqrt()\n",
    "        \n",
    "        # Get the edges pairwise distances in the global layer\n",
    "        row, col = radius(pos, pos, self.cutoff, batch, batch, max_num_neighbors=500)\n",
    "        edge_index_g = torch.stack([row, col], dim=0)\n",
    "        edge_index_g, _ = remove_self_loops(edge_index_g)\n",
    "        j_g, i_g = edge_index_g\n",
    "        dist_g = (pos[i_g] - pos[j_g]).pow(2).sum(dim=-1).sqrt()\n",
    "        \n",
    "        # Compute the node indices for defining the angles\n",
    "        idx_i_1, idx_j, idx_k, idx_kj, idx_ji, idx_i_2, idx_j1, idx_j2, idx_jj, idx_ji_2 = self.indices(edge_index_l, num_nodes=h.size(0))\n",
    "\n",
    "        # Compute the two-hop angles\n",
    "        pos_ji_1, pos_kj = pos[idx_j] - pos[idx_i_1], pos[idx_k] - pos[idx_j]\n",
    "        a = (pos_ji_1 * pos_kj).sum(dim=-1)\n",
    "        b = torch.cross(pos_ji_1, pos_kj).norm(dim=-1)\n",
    "        angle_1 = torch.atan2(b, a)\n",
    "\n",
    "        # Compute the one-hop angles\n",
    "        pos_ji_2, pos_jj = pos[idx_j1] - pos[idx_i_2], pos[idx_j2] - pos[idx_j1]\n",
    "        a = (pos_ji_2 * pos_jj).sum(dim=-1)\n",
    "        b = torch.cross(pos_ji_2, pos_jj).norm(dim=-1)\n",
    "        angle_2 = torch.atan2(b, a)\n",
    "\n",
    "        # Get the RBF and SBF embeddings\n",
    "        rbf_g = self.rbf_g(dist_g)\n",
    "        rbf_l = self.rbf_l(dist_l)\n",
    "        sbf_1 = self.sbf(dist_l, angle_1, idx_kj)\n",
    "        sbf_2 = self.sbf(dist_l, angle_2, idx_jj)\n",
    "        \n",
    "        rbf_g = self.rbf_g_mlp(rbf_g)\n",
    "        rbf_l = self.rbf_l_mlp(rbf_l)\n",
    "        sbf_1 = self.sbf_1_mlp(sbf_1)\n",
    "        sbf_2 = self.sbf_2_mlp(sbf_2)\n",
    "        \n",
    "        # Perform the message passing schemes\n",
    "        node_sum = 0\n",
    "\n",
    "        for layer in range(self.n_layer):\n",
    "            h = self.global_layers[layer](h, rbf_g, edge_index_g)\n",
    "            h, t = self.local_layers[layer](h, rbf_l, sbf_1, sbf_2, idx_kj, idx_ji, idx_jj, idx_ji_2, edge_index_l)\n",
    "            node_sum += t\n",
    "        \n",
    "        # Readout\n",
    "        output = global_add_pool(node_sum, batch)\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525191e",
   "metadata": {},
   "source": [
    "# Predict G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabc974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Double_MXMNET(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Double_MXMNET, self).__init__()\n",
    "\n",
    "        self.ground = MXMNetG(config)\n",
    "        \n",
    "        self.excited = MXMNetEX(config)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        ground_out = self.ground(data)\n",
    "        excited_out = self.excited(data)\n",
    "        \n",
    "        out = excited_out - ground_out\n",
    "                \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ce6046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the MXMNet.\n"
     ]
    }
   ],
   "source": [
    "config = Config(dim=dim, n_layer=n_layer, cutoff=cutoff)\n",
    "model = Double_MXMNET(config)\n",
    "\n",
    "best_checkpoint = torch.load('models/Double_MXMNET_for_g.pth', map_location=device)\n",
    "model.load_state_dict(best_checkpoint)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print('Loaded the MXMNet.')\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "g_pred = test(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b43ba7",
   "metadata": {},
   "source": [
    "# Predict EX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f399e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Double_MXMNET(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Double_MXMNET, self).__init__()\n",
    "\n",
    "        self.ground = MXMNetG(config)\n",
    "        \n",
    "        self.excited = MXMNetEX(config)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        ground_out = self.ground(data)\n",
    "        excited_out = self.excited(data)\n",
    "        \n",
    "        out = ground_out - excited_out\n",
    "                \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a901806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the MXMNet.\n"
     ]
    }
   ],
   "source": [
    "config = Config(dim=dim, n_layer=n_layer, cutoff=cutoff)\n",
    "model = Double_MXMNET(config)\n",
    "\n",
    "best_checkpoint = torch.load('models/Double_MXMNET_for_ex.pth', map_location=device)\n",
    "model.load_state_dict(best_checkpoint)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print('Loaded the MXMNet.')\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "ex_pred = test(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99251fa",
   "metadata": {},
   "source": [
    "# Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af2235bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.309783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.231006</td>\n",
       "      <td>0.210665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.285344</td>\n",
       "      <td>0.268960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.393129</td>\n",
       "      <td>0.264282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.167339</td>\n",
       "      <td>0.208210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>test_452</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>0.224084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>test_453</td>\n",
       "      <td>0.171201</td>\n",
       "      <td>0.147907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>test_454</td>\n",
       "      <td>0.211920</td>\n",
       "      <td>0.168242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>test_455</td>\n",
       "      <td>0.198944</td>\n",
       "      <td>0.164223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>test_456</td>\n",
       "      <td>0.314611</td>\n",
       "      <td>0.333824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   Reorg_g  Reorg_ex\n",
       "0      test_0  0.387975  0.309783\n",
       "1      test_1  0.231006  0.210665\n",
       "2      test_2  0.285344  0.268960\n",
       "3      test_3  0.393129  0.264282\n",
       "4      test_4  0.167339  0.208210\n",
       "..        ...       ...       ...\n",
       "452  test_452  0.220338  0.224084\n",
       "453  test_453  0.171201  0.147907\n",
       "454  test_454  0.211920  0.168242\n",
       "455  test_455  0.198944  0.164223\n",
       "456  test_456  0.314611  0.333824\n",
       "\n",
       "[457 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('data/sample_submission.csv')\n",
    "submit['Reorg_ex'] = ex_pred\n",
    "submit['Reorg_g'] = g_pred\n",
    "\n",
    "submit.to_csv(f'submission.csv', index=False)\n",
    "print('Done.')\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e3ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsungsubmission",
   "language": "python",
   "name": "samsungsubmission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
